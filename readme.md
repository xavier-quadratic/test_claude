# Quadratic Labs Web Scraper

Programme Python pour scraper le site web quadratic-labs.com et retourner la liste des pages trouvÃ©es.

## FonctionnalitÃ©s

- âœ… Scraping automatique du site quadratic-labs.com
- âœ… RÃ©cupÃ©ration de toutes les pages accessibles
- âœ… Export des rÃ©sultats en JSON et TXT
- âœ… Gestion des erreurs de connexion
- âœ… Respect des bonnes pratiques (dÃ©lai entre requÃªtes)
- âœ… Logging dÃ©taillÃ© du processus

## Installation

### PrÃ©requis

- Python 3.7 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

## Utilisation

### Utilisation basique

```bash
python scraper.py
```

Cette commande va :
1. Scraper le site quadratic-labs.com
2. Afficher la liste des pages trouvÃ©es dans le terminal
3. Sauvegarder les rÃ©sultats dans deux fichiers :
   - `quadratic_labs_pages.json` (format JSON structurÃ©)
   - `quadratic_labs_pages.txt` (liste simple d'URLs)

### Utilisation avancÃ©e (en tant que module)

```python
from scraper import QuadraticLabsScraper

# CrÃ©er une instance du scraper
scraper = QuadraticLabsScraper()

# Lancer le scraping (max 100 pages, dÃ©lai de 0.5s entre requÃªtes)
pages = scraper.scrape(max_pages=100, delay=0.5)

# Afficher les rÃ©sultats
print(f"Pages trouvÃ©es: {len(pages)}")
for page in pages:
    print(page)

# Sauvegarder les rÃ©sultats
scraper.save_to_json("my_results.json")
scraper.save_to_txt("my_results.txt")
```

## Configuration

Vous pouvez modifier les paramÃ¨tres dans le fichier [scraper.py](scraper.py) :

- `max_pages` : Nombre maximum de pages Ã  scraper (dÃ©faut: 100)
- `delay` : DÃ©lai en secondes entre chaque requÃªte (dÃ©faut: 0.5)
- `base_url` : URL de base Ã  scraper (dÃ©faut: "https://quadratic-labs.com")

## Format de sortie

### Fichier JSON (`quadratic_labs_pages.json`)

```json
{
  "base_url": "https://quadratic-labs.com",
  "total_pages": 42,
  "pages": [
    "https://quadratic-labs.com",
    "https://quadratic-labs.com/about",
    "https://quadratic-labs.com/contact",
    ...
  ]
}
```

### Fichier TXT (`quadratic_labs_pages.txt`)

```
https://quadratic-labs.com
https://quadratic-labs.com/about
https://quadratic-labs.com/contact
...
```

## Fonctionnement

Le scraper utilise une approche de parcours en largeur (BFS) :

1. Commence par l'URL de base
2. Extrait tous les liens de la page
3. Filtre les liens pour ne garder que ceux du mÃªme domaine
4. Visite rÃ©cursivement chaque nouveau lien trouvÃ©
5. S'arrÃªte aprÃ¨s avoir visitÃ© le nombre maximum de pages

## Gestion des erreurs

Le scraper gÃ¨re automatiquement :
- âŒ Erreurs de connexion (timeout, DNS, etc.)
- âŒ Erreurs HTTP (404, 500, etc.)
- âŒ Pages invalides ou inaccessibles

Les erreurs sont loggÃ©es mais n'interrompent pas le processus de scraping.

## Bonnes pratiques

- â±ï¸ DÃ©lai entre les requÃªtes pour ne pas surcharger le serveur
- ğŸ” User-Agent configurÃ© pour identifier le scraper
- ğŸ“ Normalisation des URLs pour Ã©viter les doublons
- ğŸ”’ Filtrage par domaine pour rester sur le site cible

## DÃ©pendances

- `requests` : Pour les requÃªtes HTTP
- `beautifulsoup4` : Pour le parsing HTML
- `lxml` : Parser rapide pour BeautifulSoup

## Licence

Ce projet est fourni tel quel, pour usage Ã©ducatif et professionnel.

## Issue GitHub

Ce projet rÃ©pond Ã  l'issue #1 : [CrÃ©er un programme Python pour scraper quadratic-labs.com](https://github.com/xavier-quadratic/test_claude/issues/1)
